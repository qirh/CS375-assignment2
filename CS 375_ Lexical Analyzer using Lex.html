
<!-- saved from url=(0050)https://www.cs.utexas.edu/users/novak/asg-lex.html -->
<html><!--  asg-lex.html          G. Novak           22 Aug 16    --><!--    --><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <title>CS 375: Lexical Analyzer using Lex</title>
</head>
<body>

<h2>CS 375: Lexical Analyzer using Lex</h2>

<h3>Due: September 22, 2016.</h3>
<p>
Redo the lexical analyzer for Pascal,
with the same specifications as in the previous assignment, but
using the Lex system to generate the syntactic analysis program.
</p><p>
Lex is described in the textbook in Section 3.5 .  There is a <tt>man</tt>
description of <tt>lex</tt> on-line; also see the file <tt>commentsinlex.txt</tt> for
useful hints on handling comments in Lex.  Several books on Lex and Yacc
are available, although you should not need them for this assignment.
<a href="https://www.cs.utexas.edu/users/novak/lexpaper.htm">
<tt>http://www.cs.utexas.edu/users/novak/lexpaper.htm </tt> </a>
is a paper on <tt>lex</tt>.
<a href="http://flex.sourceforge.net/">
<tt>http://flex.sourceforge.net/ </tt></a>
has the manual on Flex (free software version of Lex).
</p><p>
Lex allows the tokens of a language to be described using regular expressions.
The Lex compiler compiles these to produce finite automaton tables for
an automaton to parse the language.  When a complete token has been
found, user-specified actions (written in C) are executed to
produce the desired output.  Lex always produces two outputs:
</p><ol>
<li> <i>What is it?</i>: the kind of token that was found.  This is the
<tt>return()</tt> value, a small integer, e.g. <tt>return(NUMBER)</tt>.
</li><li> The <i>value</i> of the token that was found.  This is returned as a
side-effect by setting the variable <tt>yylval</tt> to the value;
for our purposes, <tt>yylval</tt> will always be of type <tt>TOKEN</tt>.
</li></ol>
<p>
Lex allows a lexical analyzer to be constructed more easily than
by writing one as a program.  For this assignment, it <b>is</b> allowable
to use C library routines such as <tt>sscanf</tt> to help with number
conversion.
</p><p>
Several files are provided to help you get started.  The file <tt>lexasu.l</tt>
is an implementation of a simple Lex scanner similar to that shown in
Figure 3.18 in the book.  You can try this program with the following
commands and data to Unix:
</p><p>
<table>
<tbody><tr><td> <tt>  make lexasu        </tt>
   </td><td>   Use lex to compile <tt>lexasu.l --&gt; lexasu.c --&gt; lexasu </tt></td></tr>
<tr><td> <tt>  lexasu                      </tt>
   </td><td>   Execute compiled <tt>lexasu</tt></td></tr>
<tr><td> <tt>  if switch then 3.14 else 4 </tt>
   </td><td>   Test data</td></tr>
<tr><td> <tt>  ^D                         </tt>
   </td><td>   Control-D for end of file to stop.</td></tr>
</tbody></table>
</p><p>
The file <tt>lex2.l</tt> creates tokens similar to the ones
in the first assignment; you can try it as follows:
</p><p>
<table>
<tbody><tr><td> <tt>  make lex2        </tt>
   </td><td>   Use lex to compile <tt>lex2.l --&gt; lex2.c --&gt; lex2 </tt></td></tr>
<tr><td> <tt>  lex2                      </tt>
   </td><td>   Execute compiled <tt>lex2</tt></td></tr>
<tr><td> <tt>  if x &gt; y then 3.14 else 4.5 </tt>
   </td><td>   Test data</td></tr>
<tr><td> <tt>  ^D                         </tt>
   </td><td>   Control-D for end of file to stop.</td></tr>
</tbody></table>
</p><p>
 You can copy <tt>lex2.l</tt> to <tt>lexan.l</tt>
(<tt>cp lex2.l lexan.l</tt>) and use <tt>lexan.l</tt> as the
starting point for your program; <tt>lexan.l</tt> can be run using
<tt>make lexer </tt> as described in comments in the file.
</p><p>
</p><h3>Testing:</h3>
<p>
Test your program on the files <tt>graph1.pas</tt>
and <tt>scantst.pas </tt> .  Error checking for numbers out of range
is <b>not</b> required for this assignment.  How well does the lex
program work on the difficult cases of <tt>scantst.pas</tt>?  Is it
as robust as your hand-written lexical analyzer?




</p></body></html>